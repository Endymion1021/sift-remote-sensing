{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "modules & envs"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "import math\n",
    "import os,sys\n",
    "import scipy.ndimage\n",
    "import time\n",
    "import scipy\n",
    "from numpy.linalg import det, lstsq, norm\n",
    "from functools import cmp_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "首先，定义一个CSift类，用于传递SIFT所需的多个参数\n",
    "'''\n",
    "class  CSift: \n",
    "\tdef __init__(self,num_octave,sigma): \n",
    "\t\t'''\n",
    "\t\t调用CSift类的时候，除初始化的一般参数外，还需要传入三个参数：\n",
    "\t\tnum_octave: 高斯金字塔的组数\n",
    "\t\tsigma: 标准差，每一层对应的都不同\n",
    "\t\t'''\n",
    "\t\tself.sigma = sigma\t# 初始尺度因子\n",
    "\t\tself.num_octave = 3 # 组数，后续重新计算\n",
    "\t\t'''\n",
    "\t\t以下参数为常量\n",
    "\t\t'''\n",
    "\t\tself.num_scale = 3 # 根据Lowe建议选择\n",
    "\t\tself.contrast_t = 0.04 # 弱响应对比度阈值\n",
    "\t\tself.eigenvalue_r = 10 # hessian矩阵特征值的比值阈值\n",
    "\t\tself.scale_factor = 1.5 # 求取方位信息时的尺度系数\n",
    "\t\tself.radius_factor = 3 # 被采样率\n",
    "\t\tself.num_bins = 36 # 极值点方位方向划分\n",
    "\t\tself.peak_ratio = 0.8 # 极值点方向分配时，辅方向的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 构建尺度空间（被称为高斯金字塔）：图像降采样+高斯模糊\n",
    "\n",
    "    Lowe论文原文：Of course, if we pre-smooth the image before extrema detection, we are effectively discarding the highest spatial frequencies. Therefore, to make full use of the input, the image can be expanded to <u>create more sample points</u> than were present in the original. We **double the size of the input image** using <u>*linear interpolation*</u> prior to building the first level of the pyramidamid.\n",
    "\n",
    "    首先通过cv2.resize方法，对原始图像进行2x缩放+高斯模糊，作为高斯金字塔的底层图像。目的是充分利用图像的空间结构信息。\n",
    "\n",
    "    效果：最终匹配得到的特征点对数量，提升四倍之多！\n",
    "\n",
    "> 注：cv2.resize插值方法：\n",
    "> + INTER_NEAREST 最近邻插值\n",
    "> + INTER_LINEAR 双线性插值（默认设置）\n",
    "> + INTER_AREA 使用像素区域关系进行重采样。\n",
    "> + INTER_CUBIC 4x4像素邻域的双三次插值\n",
    "> + INTER_LANCZOS4 8x8像素邻域的Lanczos插值\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得高斯金字塔的底层图像\n",
    "def get_base_img(img_src,sigma,cam_blur=0.5):\n",
    "    '''\n",
    "    img_src:输入原始图像\n",
    "    sigma:尺度因子\n",
    "    cam_blur: Lowe在论文中提出,原始图像的最小原始模糊sigma=0.5,防止混叠所需达到的最小值\n",
    "    在这一步操作中，进行高斯模糊操作时需要注意折算cam_blur的效果（根据高斯模糊的性质）\n",
    "    '''\n",
    "    sigma_cor = np.sqrt(sigma**2 - (2*cam_blur)**2) # 2x缩放后的图像有2x的像素间隔，所以cam_blur也为2x\n",
    "    img = img_src.copy()\n",
    "    img = cv2.resize(img,dsize=None,fx=2,fy=2,interpolation=cv2.INTER_LINEAR) # cv2.resize 2x缩放\n",
    "    img = cv2.GaussianBlur(img,ksize=None,sigmaX=sigma_cor,sigmaY=sigma_cor) # 对缩放后图像进行高斯模糊\n",
    "    # 以折算后的尺度因子生成高斯卷积核，cv2.GaussianBlur方法调用了:\n",
    "    # 1. cv2.GetGaussianKernal，分别生成两个一维高斯卷积核KernalX、KernalY；\n",
    "    # 2. cv2.sepFilter2D，用kernalX对图像行做卷积，KernalY对图像列做卷积；\n",
    "    # 最后对图像做归一化处理。\n",
    "    return img # 得到底层图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算高斯金字塔的组数\n",
    "def get_num_of_octave(img):\n",
    "\tnum = round(np.log(min(img.shape[0],img.shape[1]))/np.log(2))-1 \n",
    "\t# o = log{2}{min(x,y)}-t，其中t=log{2}{min(x,y)(顶层图像)}\n",
    "\t# 本例中底层的图像尺寸为1220*1880，顶层图像尺寸为2*4, 因此t=1\n",
    "\treturn num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建高斯金字塔\n",
    "def construct_octave(img_src,s,sigma):\n",
    "    '''\n",
    "    s: 对单个octave的划分，对图像进行高斯模糊的期望次数\n",
    "    '''\n",
    "    octave = []\n",
    "    octave.append(img_src)\n",
    "    k = 2**(1/s) # octave的每个划分之间的尺度系数，保证顶层和底层的2x尺度关系\n",
    "    for i in range(1,s+3): \n",
    "        '''\n",
    "        这里进行了s+3次尺度滤波，因为Lowe认为额外的三次滤波的意义，是\"so that final extrema detection covers a complete octave.\"\n",
    "        但是3从何而来?s个极值点检测结果需要s+2个差分层(头尾各+1)，需要(s+2)+1个高斯滤波层。\n",
    "        可以发现，进行到s+1次滤波时，对应的sigma就是2x本octave的sigma_0，正好是下一octave的sigma_0\n",
    "        根据Lowe在原文中给出的建议，选取s=3\n",
    "        '''\n",
    "        img = octave[-1].copy()\n",
    "        cur_sigma = k**i*sigma # 当前尺度 \n",
    "        pre_sigma = k**(i-1)*sigma # 前一图像尺度\n",
    "        true_sigma = np.sqrt(cur_sigma**2-pre_sigma**2) # 折算后本层对应尺度因子\n",
    "        blur_img = cv2.GaussianBlur(img,ksize=None,sigmaX=true_sigma,sigmaY=true_sigma)\n",
    "        octave.append(blur_img)\n",
    "    return octave\n",
    "\n",
    "def construct_gaussian_pyramid(img_src,sift:CSift):\n",
    "    '''\n",
    "    高斯金字塔的部分关键参数，通过CSift类传递\n",
    "    调用前要先重新计算sift.num_octave参数\n",
    "    '''\n",
    "    pyr=[]\n",
    "    img_base = img_src.copy()\n",
    "    for i in range(sift.num_octave):\n",
    "        octave = construct_octave(img_base,sift.num_scale,sift.sigma) \n",
    "        pyr.append(octave)\n",
    "        img_base = octave[-3] # 选取第s+1层的图像，作为下一个octave的输入图像，二者尺度相同\n",
    "        '注意：此处不需要模糊，直接降采样输入给下一个octave即可'\n",
    "        # img_base = cv2.resize(img_base,(int(img_base.shape[1]/2),int(img_base.shape[0]/2)),interpolation=cv2.INTER_NEAREST)\n",
    "        img_base = cv2.resize(img_base,dsize=None,fx=0.5,fy=0.5,interpolation=cv2.INTER_NEAREST)\n",
    "    return pyr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 寻找极值点的位置\n",
    "    + 构建高斯差分金字塔\n",
    "    + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建高斯差分金字塔\n",
    "def construct_DoG_pyramid(g_pyr,sift:CSift):\n",
    "    dog_pyr = []\n",
    "    for i in range(len(g_pyr)):\n",
    "        octave = g_pyr[i]\n",
    "        dog_octave = []\n",
    "        dog_octave = ((octave[k+1]-octave[k] for k in range(len(g_pyr)-1))) # 生成s+2个差分层\n",
    "        dog_pyr.append(dog_octave)\n",
    "    return dog_pyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在DoG金字塔同一octave的三个相邻层中3*3*3的区域，寻找极值点\n",
    "def is_extreme(bot,mid,top,thr):\n",
    "\t'''\n",
    "\t\n",
    "\t'''\n",
    "\tc = mid[1][1]\n",
    "\ttemp = np.concatenate([bot,mid,top],axis=0)\n",
    "\tif c>thr:\n",
    "\t\tindex1 = temp>c\n",
    "\t\tflag1 = len(np.where(index1 == True)[0]) > 0\n",
    "\t\treturn not flag1\n",
    "\telif c<-thr:\n",
    "\t\tindex2 = temp<c\n",
    "\t\tflag2 = len(np.where(index2 == True)[0]) > 0\n",
    "\t\treturn not flag2\n",
    "\treturn False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_points(g_pyr,dog_pyr,sift:CSift):\n",
    "\t'''\n",
    "\tthreshold是根据原始图像\n",
    "\tnum_scale即是S，单个octave内的划分数量\n",
    "\t'''\n",
    "\tk_p = []\n",
    "\tthreshold = np.floor(0.5 * sift.contrast_t / sift.num_scale * 255)\n",
    "\tfor octave_index in range(len(dog_pyr)):\n",
    "\t\toctave = dog_pyr[octave_index] #获取当前组下高斯差分层list\n",
    "\t\tfor s in range(1,len(octave)-1):#遍历每一层（第1层到倒数第2层）\n",
    "\t\t\tbot_img,mid_img,top_img = octave[s-1],octave[s],octave[s+1] #获取3层图像数据\n",
    "\t\t\tboard_width = 5 \n",
    "\t\t\t'边界宽度，什么作用？'\n",
    "\t\t\tx_st, y_st= board_width, board_width\n",
    "\t\t\tx_ed, y_ed = bot_img.shape[0]-board_width,bot_img.shape[1]-board_width\n",
    "\t\t\tfor i in range(x_st,x_ed):#遍历中间层图像的所有x\n",
    "\t\t\t\tfor j in range(y_st,y_ed):#遍历中间层图像的所有y\n",
    "\t\t\t\t\tflag = is_extreme(bot_img[i-1:i+2,j-1:j+2],mid_img[i-1:i+2,j-1:j+2],top_img[i-1:i+2,j-1:j+2],threshold)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif flag:#若初始判断为极值，则尝试拟合获取精确极值位置\n",
    "\t\t\t\t\t\treu = try_fit_extreme(octave,s,i,j,board_width,octave_index,sift)\n",
    "\t\t\t\t\t\tif reu is not None:#若插值成功，则求取方向信息，\n",
    "\t\t\t\t\t\t\tkp,stemp = reu\n",
    "\t\t\t\t\t\t\tkp_orientation =  compute_orientation(kp,octave_index,gau_pyr[octave_index][stemp],sift)\n",
    "\t\t\t\t\t\t\tfor k in kp_orientation:#将带方向信息的关键点保存\n",
    "\t\t\t\t\t\t\t\tkey_points.append(k)\n",
    "\treturn key_points\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def try_fit_extreme(octave,s,i,j,board_width,octave_index,sift:CSift):\n",
    "\tflag = False\n",
    "\t# 1. 尝试拟合极值点位置\n",
    "\tfor n in range(5):# 共计尝试5次\n",
    "\t\tbot_img, mid_img, top_img = octave[s - 1], octave[s], octave[s + 1]\n",
    "\t\tg,h,offset = fit_extreme(bot_img[i - 1:i + 2, j - 1:j + 2], mid_img[i - 1:i + 2, j - 1:j + 2],top_img[i - 1:i + 2, j - 1:j + 2])\n",
    "\t\tif(np.max(abs(offset))<0.5):#若offset的3个维度均小于0.5，则成功跳出\n",
    "\t\t\tflag = True\n",
    "\t\t\tbreak\n",
    "\t\ts,i,j=round(s+offset[2]),round(i+offset[1]),round(j+offset[0])#否则，更新3个维度的值，重新尝试拟合\n",
    "\t\tif i<board_width or i>bot_img.shape[0]-board_width or j<board_width or j>bot_img.shape[1]-board_width or s<1 or s>len(octave)-2:#若超出边界，直接退出\n",
    "\t\t\tbreak\n",
    "\tif not flag:\n",
    "\t\treturn None\n",
    "\t# 2. 拟合成功，计算极值\n",
    "\tex_value = mid_img[i,j]/255+0.5*np.dot(g, offset)#求取经插值后的极值\n",
    "\tif np.abs(ex_value)*sift.num_scale<sift.contrast_t: #再次进行弱响应剔除\n",
    "\t\treturn None\n",
    "\t# 3. 消除边缘响应\n",
    "\thxy=h[0:2,0:2] #获取关于x、y的hessian矩阵\n",
    "\ttrace_h = np.trace(hxy) #求取矩阵的迹\n",
    "\tdet_h = det(hxy) #求取矩阵的行列式\n",
    "\t# 若hessian矩阵的特征值满足条件（认为不是边缘）\n",
    "\tif det_h>0 and (trace_h**2/det_h)<((sift.eigenvalue_r+1)**2/sift.eigenvalue_r):\n",
    "\t\tkp = cv2.KeyPoint()\n",
    "\t\tkp.response = abs(ex_value)#保存响应值\n",
    "\t\ti,j = (i+offset[1]),(j+offset[0])#更新精确x、y位置\n",
    "\t\tkp.pt =  j/bot_img.shape[1],i/bot_img.shape[0] #这里保存坐标的百分比位置，免去后续在不同octave上的转换\n",
    "\t\tkp.size = sift.sigma*(2**( (s+offset[2])/sift.num_scale) )* 2**(octave_index)# 保存sigma(o,s)\n",
    "\t\tkp.octave = octave_index + s * (2 ** 8) + int(round((offset[2] + 0.5) * 255)) * (2 ** 16)# 低8位存放octave的index，中8位存放s整数部分，剩下的高位部分存放s的小数部分\n",
    "\t\treturn kp,s\n",
    "\treturn None\n",
    "\n",
    "def fit_extreme(bot,mid,top):#插值求极值\n",
    "\tarr = np.array([bot,mid,top])/255\n",
    "\tg = get_gradient(arr)\n",
    "\th = get_hessian(arr)\n",
    "\trt =   -lstsq(h, g, rcond=None)[0]#求解方程组\n",
    "\treturn g,h,rt\n",
    "\n",
    "def get_gradient(arr): #获取一阶梯度\n",
    "\tdx = (arr[1,1,2]-arr[1,1,0])/2\n",
    "\tdy = (arr[1,2,1] - arr[1,0,1])/2\n",
    "\tds = (arr[2,1,1] - arr[0,1,1])/2\n",
    "\treturn np.array([dx, dy, ds])\n",
    "def get_hessian(arr): #获取三维hessian矩阵\n",
    "\tdxx = arr[1,1,2]-2*arr[1,1,1] + arr[1,1,0]\n",
    "\tdyy = arr[1,2,1]-2*arr[1,1,1] + arr[1,0,1]\n",
    "\tdss = arr[2,1,1]-2*arr[1,1,1] + arr[0,1,1]\n",
    "\tdxy = 0.25*( arr[1,0,0]+arr[1,2,2]-arr[1,0,2] - arr[1,2,0]  )\n",
    "\tdxs = 0.25*( arr[0,1,0]+arr[2,1,2] -arr[0,1,2] - arr[2,1,0])\n",
    "\tdys = 0.25*( arr[0,0,1]+arr[2,2,1]- arr[0,2,1] -arr[2,0,1])\n",
    "\treturn np.array([[dxx,dxy,dxs],[dxy,dyy,dys],[dxs,dys,dss]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "if __name__ == '__main__':\n",
    "    sift = CSift(num_octave=4,sigma=1.6)\n",
    "    img_src1 = cv2.imread('remote_sensing_pair/image1.bmp',-1)\n",
    "    # img_src2 = cv2.imread('remote_sensing_pair/image2.bmp',-1)\n",
    "\n",
    "    sift.num_octave = get_num_of_octave(img_src1)\n",
    "    base_img1 = get_base_img(img_src1,sigma=sift.sigma,cam_blur=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_sift(img_src,sift:CSift):\n",
    "\timg = img_src.copy().astype(np.float32)\n",
    "\timg = get_base_img(img,sift.sigma)\n",
    "\tsift.num_octave = get_num_of_octave(img)\n",
    "\tgaussian_pyr = construct_gaussian_pyramid(img,sift)\n",
    "\tdog_pyr = construct_DoG_pyramid(gaussian_pyr)\n",
    "\tkey_points = get_keypoints(gaussian_pyr,dog_pyr,sift)\n",
    "\tkey_points = remove_duplicate_points(key_points)\n",
    "\tdescriptor = get_descriptor(key_points,gaussian_pyr)\n",
    "\treturn key_points,descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_match(img_src1,kp1,des1,img_src2,kp2,des2,embed=1,pt_flag=0,MIN_MATCH_COUNT = 10):\n",
    "\t## 1. 对关键点进行匹配 ##\n",
    "\tFLANN_INDEX_KDTREE = 0\n",
    "\tindex_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "\tsearch_params = dict(checks=50)\n",
    "\tflann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\tdes1, des2 = np.array(des1).astype(np.float32), np.array(des2).astype(np.float32)#需要转成array\n",
    "\tmatches = flann.knnMatch(des1, des2, k=2)  # matches为list，每个list元素由2个DMatch类型变量组成,分别是最邻近和次邻近点\n",
    "\n",
    "\tgood_match = []\n",
    "\tfor m in matches:\n",
    "\t\tif m[0].distance < 0.7 * m[1].distance:  # 如果最邻近和次邻近的距离差距较大,则认可\n",
    "\t\t\tgood_match.append(m[0])\n",
    "\t## 2. 将2张图画在同一张图上 ##\n",
    "\timg1 = img_src1.copy()\n",
    "\timg2 = img_src2.copy()\n",
    "\th1, w1 = img1.shape[0],img1.shape[1]\n",
    "\th2, w2 = img2.shape[0],img2.shape[1]\n",
    "\tnew_w = w1 + w2\n",
    "\tnew_h = np.max([h1, h2])\n",
    "\tnew_img =  np.zeros((new_h, new_w,3), np.uint8) if len(img_src1.shape)==3 else  np.zeros((new_h, new_w), np.uint8)\n",
    "\th_offset1 = int(0.5 * (new_h - h1))\n",
    "\th_offset2 = int(0.5 * (new_h - h2))\n",
    "\tif len(img_src1.shape) == 3:\n",
    "\t\tnew_img[h_offset1:h_offset1 + h1, :w1,:] = img1  # 左边画img1\n",
    "\t\tnew_img[h_offset2:h_offset2 + h2, w1:w1 + w2,:] = img2  # 右边画img2\n",
    "\telse:\n",
    "\t\tnew_img[h_offset1:h_offset1 + h1, :w1] = img1  # 左边画img1\n",
    "\t\tnew_img[h_offset2:h_offset2 + h2, w1:w1 + w2] = img2  # 右边画img2\n",
    "\t##3. 两幅图存在足够的匹配点，两幅图匹配成功，将匹配成功的关键点进行连线 ##\n",
    "\tif len(good_match) > MIN_MATCH_COUNT:\n",
    "\t\tsrc_pts = []\n",
    "\t\tdst_pts = []\n",
    "\t\tmag_err_arr=[]\n",
    "\t\tangle_err_arr=[]\n",
    "\t\tfor m in good_match:\n",
    "\t\t\tif pt_flag==0:#point是百分比\n",
    "\t\t\t\tsrc_pts.append([kp1[m.queryIdx].pt[0] * img1.shape[1], kp1[m.queryIdx].pt[1] * img1.shape[0]])#保存匹配成功的原图关键点位置\n",
    "\t\t\t\tdst_pts.append([kp2[m.trainIdx].pt[0] * img2.shape[1], kp2[m.trainIdx].pt[1] * img2.shape[0]])#保存匹配成功的目标图关键点位置\n",
    "\t\t\telse:\n",
    "\t\t\t\tsrc_pts.append([kp1[m.queryIdx].pt[0], kp1[m.queryIdx].pt[1]])  # 保存匹配成功的原图关键点位置\n",
    "\t\t\t\tdst_pts.append([kp2[m.trainIdx].pt[0], kp2[m.trainIdx].pt[1]])  # 保存匹配成功的目标图关键点位置\n",
    "\n",
    "\t\t\tmag_err = np.abs(kp1[m.queryIdx].response - kp2[m.trainIdx].response) / np.abs(kp1[m.queryIdx].response )\n",
    "\t\t\tangle_err = np.abs(kp1[m.queryIdx].angle - kp2[m.trainIdx].angle)\n",
    "\t\t\tmag_err_arr.append(mag_err)\n",
    "\t\t\tangle_err_arr.append(angle_err)\n",
    "\n",
    "\t\tif embed!=0 :#若图像2是图像1内嵌入另一个大的背景中，则在图像2中，突出显示图像1的边界\n",
    "\t\t\tM = cv2.findHomography(np.array(src_pts), np.array(dst_pts), cv2.RANSAC, 5.0)[0]  # 根据src和dst关键点，寻求变换矩阵\n",
    "\t\t\tsrc_w, src_h = img1.shape[1], img1.shape[0]\n",
    "\t\t\tsrc_rect = np.array([[0, 0], [src_w - 1, 0], [src_w - 1, src_h - 1], [0, src_h - 1]]).reshape(-1, 1, 2).astype(\n",
    "\t\t\t\tnp.float32)  # 原始图像的边界框\n",
    "\t\t\tdst_rect = cv2.perspectiveTransform(src_rect, M)  # 经映射后，得到dst的边界框\n",
    "\t\t\timg2 = cv2.polylines(img2, [np.int32(dst_rect)], True, 255, 3, cv2.LINE_AA)  # 将边界框画在dst图像上，突出显示\n",
    "\t\t\tif len(new_img.shape) == 3:\n",
    "\t\t\t\tnew_img[h_offset2:h_offset2 + h2, w1:w1 + w2,:] = img2  # 右边画img2\n",
    "\t\t\telse:\n",
    "\t\t\t\tnew_img[h_offset2:h_offset2 + h2, w1:w1 + w2] = img2  # 右边画img2\n",
    "\n",
    "\t\tnew_img = new_img if len(new_img.shape) == 3 else  cv2.cvtColor(new_img, cv2.COLOR_GRAY2BGR)\n",
    "\t\t# 连线\n",
    "\t\tfor pt1, pt2 in zip(src_pts, dst_pts):\n",
    "\t\t\tcv2.line(new_img, tuple(np.int32(np.array(pt1) + [0, h_offset1])),\n",
    "\t\t\t\t\t tuple(np.int32(np.array(pt2) + [w1, h_offset2])), color=(0, 0, 255))\n",
    "\treturn new_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用OpenCV库中的cv2.SIFT.create方法实现SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\tMIN_MATCH_COUNT = 10\n",
    "\tsift = CSift(num_octave=4,sigma=1.6)\n",
    "\timg_src1 = cv2.imread('remote_sensing_pair\\image1.bmp',-1)\n",
    "\t#img_src1 = cv2.resize(img_src1, (0, 0), fx=.25, fy=.25)\n",
    "\timg_src2 = cv2.imread('remote_sensing_pair\\image2.bmp', -1)\n",
    "\t#img_src2 = cv2.resize(img_src2, (0, 0), fx=.5, fy=.5)\n",
    "\t# # 2. 使用opencv自带sift算子\n",
    "\t# sift.num_octave = get_numOfOctave(img_src1)\n",
    "\t# opencv_sift = cv2.SIFT.create(nfeatures=None, nOctaveLayers=sift.num_octave,\n",
    "\t# \t\t\t\t\t\t\t  contrastThreshold=sift.contrast_t, edgeThreshold=sift.eigenvalue_r, sigma=sift.sigma)\n",
    "\t# kp1 = opencv_sift.detect(img_src1)\n",
    "\t# kp1,des1 = opencv_sift.compute(img_src1,kp1)\n",
    "\n",
    "\t# sift.num_octave = get_numOfOctave(img_src2)\n",
    "\t# opencv_sift = cv2.SIFT.create(nfeatures=None, nOctaveLayers=sift.num_octave,\n",
    "\t# \t\t\t\t\t\t\t  contrastThreshold=sift.contrast_t, edgeThreshold=sift.eigenvalue_r, sigma=sift.sigma)\n",
    "\t# kp2 = opencv_sift.detect(img_src2)\n",
    "\t# kp2, des2 = opencv_sift.compute(img_src2, kp2)\n",
    "\t# pt_flag = 1\n",
    "\n",
    "\t# # 3. 做匹配\n",
    "\t# reu_img = do_match(img_src1, kp1, des1, img_src2, kp2, des2, embed=1, pt_flag=pt_flag,MIN_MATCH_COUNT=3)\n",
    "\t# cv2.imshow('reu',reu_img)\n",
    "\t# cv2.imwrite('reu.tif',reu_img)\n",
    "\t# '''\n",
    "\t# 最初cv2.imshow方法弹出的图像显示窗口无响应，查阅资料后增加以下办法，\n",
    "\t# 通过调用destroyWindows()函数来释放由OpenCV创建的所有窗口\n",
    "\t# '''\n",
    "\t# cv2.waitKey(1000)\n",
    "\t# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0d6b6dc656e6d1fe47061097bcd586bf57ac400415973bea440c4e9f7223950"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
